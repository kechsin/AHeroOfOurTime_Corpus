{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxod2K9HCiqwYVc78lDweL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install stanza\n",
        "!pip install nltk"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tyoco4DwndA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "aSxINcVcmBqd"
      },
      "outputs": [],
      "source": [
        "from string import punctuation\n",
        "import re\n",
        "import csv\n",
        "import sys\n",
        "import stanza\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Открываю файл text.csv, немного чищу и разделяю на предложения, сохраняю в sentences."
      ],
      "metadata": {
        "id": "6931jeQhBalL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clear(line):  # эта функция хорошо работает только с этим текстом, потому что я его рассмотрела, и нашла, что убрать\n",
        "    clear_txt = re.sub(\"\\* .*(\\(Примеч\\. Лермонтова\\.\\)|Ред\\.)\", \"\", line)  # убираем Примечания, потому что они посреди других предложений находятся\n",
        "    clear_txt = re.sub('[^С*]\\*', \"\", clear_txt) # убираем звёздочки от примечаний, оставляем один случай \"майор С***\" (превратится в)\n",
        "    clear_txt = re.sub('Г<осподин>', 'Господин', clear_txt)\n",
        "    return clear_txt"
      ],
      "metadata": {
        "id": "8hcRGQ5fDtlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv.field_size_limit(sys.maxsize)\n",
        "sentences = []\n",
        "with open(\"crawler_text.csv\") as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "        clear_txt = clear(row[0])\n",
        "        sentences.extend([(i.strip(), row[1]) for i in nltk.sent_tokenize(clear_txt)])"
      ],
      "metadata": {
        "id": "QGTRfTEUo0r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences2 = []\n",
        "with open(\"crawler_text.csv\") as f:\n",
        "    reader2 = csv.reader(f)\n",
        "    for row in reader2:\n",
        "        clear_txt2 = clear(row[0])\n",
        "        sentences2.extend([(i.strip(), row[1]) for i in nltk.sent_tokenize(clear_txt2)])"
      ],
      "metadata": {
        "id": "BbcE74E2TA5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences2.pop(0) # там строка заголовка"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ommxqk8Tj3g",
        "outputId": "5d9a1059-759c-45c2-81c5-ee219e5fb77c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Text', 'Part')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sentences)):\n",
        "    if sentences[i][0] != sentences2[i][0]:\n",
        "        print(sentences[i][0], sentences2[i][0])"
      ],
      "metadata": {
        "id": "G83hFrDMTPCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определяю морфологию с помощью stanza.\n",
        "Сохраняю данный в следующем формате для поиска:\n",
        "\n",
        "Мама мыла раму., (мама; мыла; раму), (мама; мыть; рама), (Noun; Verb; Noun), Про мытьё рамы. Глава 1\n",
        "\n",
        "(Скобки и пробелы только чтобы было лучше понятно здесь, их не будет в файле)"
      ],
      "metadata": {
        "id": "e9l-WTZoBmQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences.pop(0) # там строка заголовка"
      ],
      "metadata": {
        "id": "1Mlhqm6EDXqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "120aa626-6267-4f63-daa7-411a98eedef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Text', 'Part')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation += '«»—'"
      ],
      "metadata": {
        "id": "v2ojWbWzKa4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ppln = stanza.Pipeline('ru', processors='tokenize,pos,lemma')\n",
        "rows = []\n",
        "for sent, chapter in sentences:\n",
        "    words = []\n",
        "    lemmas = []\n",
        "    pos = []\n",
        "    doc = ppln(sent)\n",
        "    for snt in doc.sentences:\n",
        "        for word in snt.words:\n",
        "            if word.upos != 'PUNCT':\n",
        "                words.append(word.text)\n",
        "                lemmas.append(word.lemma)\n",
        "                pos.append(word.upos)\n",
        "    words_line = \";\".join(words)\n",
        "    lemmas_line = ';'.join(lemmas)\n",
        "    pos_line = ';'.join(pos)\n",
        "    rows.append([sent, words_line, lemmas_line, pos_line, chapter])\n"
      ],
      "metadata": {
        "id": "goWQQ_rXHtAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"corpus_data.csv\", 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['Sentence', 'Tokens', 'Lemmas', 'POS', 'Chapter'])\n",
        "    writer.writerows(rows)"
      ],
      "metadata": {
        "id": "_tor4SpcLQtc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}