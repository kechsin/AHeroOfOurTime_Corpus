{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install stanza\n",
        "!pip install nltk"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tyoco4DwndA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "aSxINcVcmBqd"
      },
      "outputs": [],
      "source": [
        "from string import punctuation\n",
        "import re\n",
        "import csv\n",
        "import sys\n",
        "import stanza\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clear(line):  # эта функция хорошо работает только с этим текстом, потому что я его рассмотрела, и нашла, что убрать\n",
        "    clear_txt = re.sub(\"\\* .*(\\(Примеч\\. Лермонтова\\.\\)|Ред\\.)\", \"\", line)  # убираем Примечания, потому что они посреди других предложений находятся\n",
        "    clear_txt = re.sub('[^С*]\\*', \"\", clear_txt) # убираем звёздочки от примечаний, оставляем один случай \"майор С***\" (превратится в)\n",
        "    clear_txt = re.sub('Г<осподин>', 'Господин', clear_txt)\n",
        "    return clear_txt"
      ],
      "metadata": {
        "id": "8hcRGQ5fDtlO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Открываю файл text.csv, немного чищу и разделяю на предложения, сохраняю в sentences."
      ],
      "metadata": {
        "id": "6931jeQhBalL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv.field_size_limit(sys.maxsize)\n",
        "sentences = []\n",
        "with open(\"crawler_text.csv\") as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "        clear_txt = clear(row[0])\n",
        "        sentences.extend([(i.strip(), row[1]) for i in nltk.sent_tokenize(clear_txt)])"
      ],
      "metadata": {
        "id": "QGTRfTEUo0r0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определяю морфологию с помощью mystem.\n",
        "Сохраняю данный в следующем формате для поиска:\n",
        "\n",
        "Мама мыла раму., (мама; мыла; раму), (мама; мыть; рама), (Noun; Verb; Noun), Про мытьё рамы. Глава 1\n",
        "\n",
        "(Скобки и пробелы только чтобы было лучше понятно здесь, их не будет в файле)"
      ],
      "metadata": {
        "id": "e9l-WTZoBmQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences.pop(0) # там строка заголовка"
      ],
      "metadata": {
        "id": "1Mlhqm6EDXqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation += '«»—'"
      ],
      "metadata": {
        "id": "v2ojWbWzKa4w"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ppln = stanza.Pipeline('ru', processors='tokenize,pos,lemma')\n",
        "rows = []\n",
        "for sent, chapter in sentences:\n",
        "    words = []\n",
        "    lemmas = []\n",
        "    pos = []\n",
        "    doc = ppln(sent)\n",
        "    for snt in doc.sentences:\n",
        "        for word in snt.words:\n",
        "            if word.upos != 'PUNCT':\n",
        "                lemmas.append(word.lemma)\n",
        "                pos.append(word.upos)\n",
        "    words_line = \";\".join(words)\n",
        "    lemmas_line = ';'.join(lemmas)\n",
        "    pos_line = ';'.join(pos)\n",
        "    rows.append([sent, words_line, lemmas_line, pos_line, chapter])\n"
      ],
      "metadata": {
        "id": "goWQQ_rXHtAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"corpus_data.csv\", 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['Sentence', 'Tokens', 'Lemmas', 'POS', 'Chapter'])\n",
        "    writer.writerows(rows)"
      ],
      "metadata": {
        "id": "_tor4SpcLQtc"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}